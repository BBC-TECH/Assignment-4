{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvM4fRPLbHy/KCuHsqehtp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BBC-TECH/Assignment-4/blob/main/Experiment4ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Experiment 4: Naive Bayes (from scratch and sklearn comparison)"
      ],
      "metadata": {
        "id": "R9tngHULUPOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "E_DHRfIXUejn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/sample_data/spam.csv\", encoding=\"latin-1\")\n",
        "\n",
        "# Drop extra unnamed/empty columns\n",
        "df = df.dropna(axis=1, how=\"all\")\n",
        "\n",
        "\n",
        "df = df.rename(columns={df.columns[0]: \"Label\", df.columns[1]: \"Message\"})\n",
        "\n",
        "# Encode labels: ham -> 0, spam -> 1\n",
        "df['Label'] = df['Label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "X = df['Message'].values\n",
        "y = df['Label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"âœ… Dataset Loaded Successfully\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnWa8lGmUxrK",
        "outputId": "f90f6d84-2b5d-48bc-d416-c3cf04c22163"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset Loaded Successfully\n",
            "   Label                                            Message\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Naive Bayes From Scratch\n",
        "\n",
        "class NaiveBayesScratch:\n",
        "    def __init__(self, alpha=1.0):  # Laplace smoothing\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.class_priors = {}\n",
        "        self.word_counts = {}\n",
        "        self.class_word_totals = {}\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X[y==c]\n",
        "            all_words = []\n",
        "            for doc in X_c:\n",
        "                all_words.extend(doc)\n",
        "            self.word_counts[c] = Counter(all_words)\n",
        "            self.class_word_totals[c] = sum(self.word_counts[c].values())\n",
        "            self.class_priors[c] = len(X_c) / len(X)\n",
        "\n",
        "        self.vocab = set()\n",
        "        for c in self.classes:\n",
        "            self.vocab.update(self.word_counts[c].keys())\n",
        "        self.vocab = list(self.vocab)\n",
        "        self.V = len(self.vocab)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "        for doc in X:\n",
        "            class_scores = {}\n",
        "            for c in self.classes:\n",
        "                log_prob = np.log(self.class_priors[c])\n",
        "                for word in doc:\n",
        "                    word_count = self.word_counts[c].get(word, 0)\n",
        "                    log_prob += np.log((word_count + self.alpha) /\n",
        "                                       (self.class_word_totals[c] + self.alpha * self.V))\n",
        "                class_scores[c] = log_prob\n",
        "            preds.append(max(class_scores, key=class_scores.get))\n",
        "        return np.array(preds)"
      ],
      "metadata": {
        "id": "2Ad_MC39Ww9S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluation Function\n",
        "def evaluate_model(vectorizer, method=\"Scratch NB\"):\n",
        "    vec = vectorizer()\n",
        "    X_train_vec = vec.fit_transform(X_train)\n",
        "    X_test_vec = vec.transform(X_test)\n",
        "\n",
        "    if method == \"Scratch NB\":\n",
        "        # Convert to tokens for scratch NB\n",
        "        X_train_tokens = [[vec.get_feature_names_out()[i] for i in X_train_vec[row].indices]\n",
        "                          for row in range(X_train_vec.shape[0])]\n",
        "        X_test_tokens = [[vec.get_feature_names_out()[i] for i in X_test_vec[row].indices]\n",
        "                         for row in range(X_test_vec.shape[0])]\n",
        "\n",
        "        nb = NaiveBayesScratch(alpha=1.0)\n",
        "        nb.fit(np.array(X_train_tokens, dtype=object), y_train)\n",
        "        y_pred = nb.predict(np.array(X_test_tokens, dtype=object))\n",
        "\n",
        "    elif method == \"Sklearn NB\":\n",
        "        nb = MultinomialNB(alpha=1.0)\n",
        "        nb.fit(X_train_vec, y_train)\n",
        "        y_pred = nb.predict(X_test_vec)\n",
        "\n",
        "    else:  # Logistic Regression\n",
        "        clf = LogisticRegression(max_iter=1000)\n",
        "        clf.fit(X_train_vec, y_train)\n",
        "        y_pred = clf.predict(X_test_vec)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nðŸ“Œ {method} with {vectorizer.__name__}\")\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"Precision:\", prec)\n",
        "    print(\"Recall:\", rec)\n",
        "    print(\"F1:\", f1)\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    return [method, vectorizer.__name__, acc, prec, rec, f1]\n"
      ],
      "metadata": {
        "id": "YOn7C35EW-c3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Run All Models\n",
        "\n",
        "results = []\n",
        "# Naive Bayes Scratch\n",
        "results.append(evaluate_model(CountVectorizer, method=\"Scratch NB\"))\n",
        "results.append(evaluate_model(TfidfVectorizer, method=\"Scratch NB\"))\n",
        "# Sklearn Naive Bayes\n",
        "results.append(evaluate_model(CountVectorizer, method=\"Sklearn NB\"))\n",
        "results.append(evaluate_model(TfidfVectorizer, method=\"Sklearn NB\"))\n",
        "# Logistic Regression\n",
        "results.append(evaluate_model(CountVectorizer, method=\"Logistic Regression\"))\n",
        "results.append(evaluate_model(TfidfVectorizer, method=\"Logistic Regression\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnXzy7waXR2l",
        "outputId": "ebb795a9-7ccd-42e8-8600-ff37e146622a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ Scratch NB with CountVectorizer\n",
            "Accuracy: 0.9847533632286996\n",
            "Precision: 0.9925373134328358\n",
            "Recall: 0.8926174496644296\n",
            "F1: 0.9399293286219081\n",
            "Confusion Matrix:\n",
            " [[965   1]\n",
            " [ 16 133]]\n",
            "\n",
            "ðŸ“Œ Scratch NB with TfidfVectorizer\n",
            "Accuracy: 0.9847533632286996\n",
            "Precision: 0.9925373134328358\n",
            "Recall: 0.8926174496644296\n",
            "F1: 0.9399293286219081\n",
            "Confusion Matrix:\n",
            " [[965   1]\n",
            " [ 16 133]]\n",
            "\n",
            "ðŸ“Œ Sklearn NB with CountVectorizer\n",
            "Accuracy: 0.9865470852017937\n",
            "Precision: 0.9855072463768116\n",
            "Recall: 0.912751677852349\n",
            "F1: 0.9477351916376306\n",
            "Confusion Matrix:\n",
            " [[964   2]\n",
            " [ 13 136]]\n",
            "\n",
            "ðŸ“Œ Sklearn NB with TfidfVectorizer\n",
            "Accuracy: 0.9596412556053812\n",
            "Precision: 1.0\n",
            "Recall: 0.697986577181208\n",
            "F1: 0.8221343873517787\n",
            "Confusion Matrix:\n",
            " [[966   0]\n",
            " [ 45 104]]\n",
            "\n",
            "ðŸ“Œ Logistic Regression with CountVectorizer\n",
            "Accuracy: 0.9802690582959641\n",
            "Precision: 1.0\n",
            "Recall: 0.8523489932885906\n",
            "F1: 0.9202898550724637\n",
            "Confusion Matrix:\n",
            " [[966   0]\n",
            " [ 22 127]]\n",
            "\n",
            "ðŸ“Œ Logistic Regression with TfidfVectorizer\n",
            "Accuracy: 0.9721973094170404\n",
            "Precision: 1.0\n",
            "Recall: 0.7919463087248322\n",
            "F1: 0.8838951310861424\n",
            "Confusion Matrix:\n",
            " [[966   0]\n",
            " [ 31 118]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Results Table\n",
        "\n",
        "results_df = pd.DataFrame(results,\n",
        "    columns=[\"Model_Type\", \"Vectorizer_Type\", \"Accuracy_Score\", \"Precision_Score\", \"Recall_Score\", \"F1_Score\"]\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“Š Final Comparative Results:\\n\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GijllCa0aJvb",
        "outputId": "13a1698c-480c-4564-f7e0-c82b58765085"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š Final Comparative Results:\n",
            "\n",
            "            Model_Type  Vectorizer_Type  Accuracy_Score  Precision_Score  \\\n",
            "0           Scratch NB  CountVectorizer        0.984753         0.992537   \n",
            "1           Scratch NB  TfidfVectorizer        0.984753         0.992537   \n",
            "2           Sklearn NB  CountVectorizer        0.986547         0.985507   \n",
            "3           Sklearn NB  TfidfVectorizer        0.959641         1.000000   \n",
            "4  Logistic Regression  CountVectorizer        0.980269         1.000000   \n",
            "5  Logistic Regression  TfidfVectorizer        0.972197         1.000000   \n",
            "\n",
            "   Recall_Score  F1_Score  \n",
            "0      0.892617  0.939929  \n",
            "1      0.892617  0.939929  \n",
            "2      0.912752  0.947735  \n",
            "3      0.697987  0.822134  \n",
            "4      0.852349  0.920290  \n",
            "5      0.791946  0.883895  \n"
          ]
        }
      ]
    }
  ]
}